{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9ccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3c943c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(production, sales):\n",
    "    data_production = production\n",
    "    data_sales = sales\n",
    "\n",
    "    # create new column 'concat' by concatenating 'Model' and 'Name' columns with '.' separator\n",
    "    data_production[\"concat\"] = data_production[\"Model\"] + \".\" + data_production[\"Name\"]  # Concatenate columns\n",
    "\n",
    "    # create new column 'ID' by hashing 'concat' column\n",
    "    data_production[\"ID\"] = data_production[\"concat\"].apply(lambda x: str(uuid.uuid5(uuid.NAMESPACE_DNS, x)))  # Hash column\n",
    "\n",
    "    # Remove column 'concat' from data_production table\n",
    "    data_production.drop(columns=[\"concat\"], inplace=True)  # Remove column\n",
    "\n",
    "    # create new column 'concat' by concatenating 'Model' and 'Name' columns with '.' separator\n",
    "    data_sales[\"concat\"] = data_sales[\"Model\"] + \".\" + data_sales[\"Name\"]  # Concatenate columns\n",
    "    # create new column 'ID' by hashing 'concat' column\n",
    "    data_sales[\"ID\"] = data_sales[\"concat\"].apply(lambda x: str(uuid.uuid5(uuid.NAMESPACE_DNS, x)))  # Hash column\n",
    "    # Remove column 'concat' from data_production table\n",
    "    data_sales.drop(columns=[\"concat\"], inplace=True)  # Remove column\n",
    "\n",
    "    data_dates = pd.read_excel(\"Date.xlsx\")\n",
    "\n",
    "    # Start processing the data\n",
    "    data_dates = data_dates[[\"Date\", \"StartOfWeek\"]]\n",
    "    data_dates.rename(columns={\"Date\": \"date\", \"StartOfWeek\": \"week_start\"}, inplace=True)  # Rename column\n",
    "    data_dates_1 = data_dates.copy()  # Copy the data_dates table\n",
    "    data_dates_1[\"date_next_week\"] = data_dates_1[\"week_start\"] + pd.DateOffset(7)  # Add 7 days to date\n",
    "\n",
    "    # Join the data_sales and data_sales tables on 'Date Sold' and 'date' columns\n",
    "    data_sales = data_sales.merge(data_dates, left_on=\"Date Sold\", right_on=\"date\", how=\"left\")\n",
    "    data_sales_1 = data_sales.copy()  # Copy the data_sales table\n",
    "\n",
    "    # Add new column 'Sold amt' in data_sales table, using 'Sold Qty' * 'Price Sold' columns\n",
    "    data_sales[\"Sold amt\"] = (data_sales[\"Sold Qty\"] * data_sales[\"Price Sold\"])  # Add new column\n",
    "\n",
    "    # Groupby by 'ID', 'Name', 'week_start' and sum the 'Sold Qty' and 'Sold amt' columns\n",
    "    data_sales_grouped = (data_sales.groupby([\"ID\", \"Name\", \"Model\", \"week_start\"])[[\"Sold Qty\", \"Sold amt\"]].sum().reset_index())\n",
    "\n",
    "    # Add new colum 'Mean(Price Sold)' in data_sales_grouped table, using 'Sold amt' / 'Sold Qty' columns\n",
    "    data_sales_grouped[\"Mean(Price Sold)\"] = (data_sales_grouped[\"Sold amt\"] / data_sales_grouped[\"Sold Qty\"])  # Add new column\n",
    "\n",
    "    # Remove column 'Sold amt' from data_sales_grouped table\n",
    "    data_sales_grouped.drop(columns=\"Sold amt\", inplace=True)  # Remove column\n",
    "\n",
    "    # Join data_sales_grouped with data_production table on 'ID' and 'week_start' columns, with 'ID' and 'Date' columns\n",
    "    data_production = data_production.merge(data_sales_grouped, left_on=[\"ID\", \"Date\"], right_on=[\"ID\", \"week_start\"], how=\"left\")\n",
    "\n",
    "    data_production.drop(columns=[\"Name_y\", \"week_start\", \"Model_y\"], inplace=True)  # Remove column\n",
    "    data_production.rename(columns={\"Name_x\": \"Name\", \"Model_x\": \"Model\"}, inplace=True)  # Rename column\n",
    "\n",
    "    # Sort data_production table by 'ID' desc and 'Date' asc columns\n",
    "    data_production.sort_values([\"ID\", \"Date\"], ascending=[False, True], inplace=True)  # Sort table\n",
    "\n",
    "    # Join data_production table with data_dates_1 table on 'Date' and 'date' columns, only keep 'date_next_week' column from data_dates_1 table\n",
    "    data_production = data_production.merge(data_dates_1[[\"date\", \"date_next_week\"]], left_on=\"Date\", right_on=\"date\", how=\"left\")\n",
    "    data_production.drop(columns=[\"date\"], inplace=True)  # Remove column\n",
    "\n",
    "    # Fill missing values in column with float type with 0\n",
    "    data_production[\"Production\"] = data_production[\"Production\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Price Submited\"] = data_production[\"Price Submited\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Sold Qty\"] = data_production[\"Sold Qty\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Mean(Price Sold)\"] = data_production[\"Mean(Price Sold)\"].fillna(0)  # Fill missing values\n",
    "\n",
    "    # Order data_production table by 'ID' and 'Date' columns\n",
    "    data_production.sort_values([\"ID\", \"Date\"], inplace=True)  # Sort table\n",
    "\n",
    "    # Add cumulative sum column 'Running Sold' of 'Sum(Sold Qty)' column by 'ID' group\n",
    "    data_production_1 = data_production.copy()  # Copy the data_production table\n",
    "    data_production_1[\"Running Sold\"] = data_production_1.groupby(\"ID\")[\"Sold Qty\"].cumsum()  # Add new column\n",
    "\n",
    "    # Add cumulative sum column 'Running Production' of 'Production' column by 'ID' group\n",
    "    data_production_1[\"Running Production\"] = data_production_1.groupby(\"ID\")[\"Production\"].cumsum()  # Add new column\n",
    "    data_production_1 = data_production_1.drop(columns=[\"Name\", \"Date\", \"Price Submited\", \"Sold Qty\", \"Mean(Price Sold)\"])  # Remove columns\n",
    "    data_production_2 = data_production.merge(data_production_1, left_on=[\"Date\", \"ID\"], right_on=[\"date_next_week\", \"ID\"], how=\"left\")  # Merge tables\n",
    "\n",
    "    # Keep columns 'ID', 'Name', 'Date', 'Production', 'Price Submited', 'Sold Qty', 'Mean(Price Sold)', 'Running Sold', 'Running Production'\n",
    "    data_production_2 = data_production_2[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Model_x\",\n",
    "            \"Name\",\n",
    "            \"Date\",\n",
    "            \"Production_x\",\n",
    "            \"Price Submited\",\n",
    "            \"Sold Qty\",\n",
    "            \"Mean(Price Sold)\",\n",
    "            \"Running Sold\",\n",
    "            \"Running Production\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # rename columns 'ID_x', 'Production_x' to 'ID', 'Production'\n",
    "    data_production_2.rename(columns={\"ID_x\": \"ID\", \"Production_x\": \"Production\", \"Model_x\": \"Model\"}, inplace=True)  # Rename columns\n",
    "    data_production_2[\"Production\"] = data_production_2[\"Production\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Price Submited\"] = data_production_2[\"Price Submited\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Sold Qty\"] = data_production_2[\"Sold Qty\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Mean(Price Sold)\"] = data_production_2[\"Mean(Price Sold)\" ].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Running Sold\"] = data_production_2[\"Running Sold\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Running Production\"] = data_production_2[\"Running Production\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Opening\"] = (data_production_2[\"Running Production\"] - data_production_2[\"Running Sold\"])  # Add new column\n",
    "    data_production_2[\"Available\"] = (data_production_2[\"Production\"] + data_production_2[\"Opening\"])  # Add new column\n",
    "    data_production_2[\"Closing\"] = (data_production_2[\"Available\"] - data_production_2[\"Sold Qty\"])  # Add new column data_production_2\n",
    "    data_production_2[\"rank\"] = data_production_2.groupby(\"ID\").cumcount()\n",
    "\n",
    "    # Add new column 'prev_available' with logic: if \"ID\" = [\"ID\",-1] then [\"Available\",-1] else 0\n",
    "    if not data_production_2[\"ID\"].shift(1).isnull().all():\n",
    "        data_production_2[\"prev_available\"] = (\n",
    "            data_production_2[\"Available\"]\n",
    "            .shift(1)\n",
    "            .where(data_production_2[\"ID\"] == data_production_2[\"ID\"].shift(1), 0)\n",
    "        )\n",
    "        \n",
    "    data_production_2[\"prev_closing\"] = data_production_2.apply(lambda row: 0 if row[\"prev_available\"] == 0 else data_production_2.loc[row.name - 1, \"Closing\"] if row.name > 0 else 0, axis=1,)\n",
    "    data_production_2[\"close_rate\"] = 0.0\n",
    "\n",
    "    # Iterate through each row to calculate 'Init rate'\n",
    "    for i in range(len(data_production_2)):\n",
    "        if data_production_2.at[i, \"rank\"] == 0:\n",
    "            data_production_2.at[i, \"close_rate\"] = data_production_2.at[\n",
    "                i, \"Price Submited\"\n",
    "            ]\n",
    "        else:\n",
    "            # Calculate using the formula with previous 'Init rate'\n",
    "            previous_init_rate = data_production_2.at[i - 1, \"close_rate\"]\n",
    "            stock_available = data_production_2.at[i, \"prev_closing\"]\n",
    "            production_weight = data_production_2.at[i, \"Production\"]\n",
    "            production_rate = data_production_2.at[i, \"Price Submited\"]\n",
    "\n",
    "            data_production_2.at[i, \"close_rate\"] = (\n",
    "                stock_available * previous_init_rate\n",
    "                + production_weight * production_rate\n",
    "            ) / (stock_available + production_weight) # data_production_2\n",
    "    data_production_2.sort_values([\"ID\", \"rank\"], ascending=[True, True], inplace=True)  # Sort table\n",
    "\n",
    "    # Add new column 'start_rate' with logic: if \"rank\" = 0 then 0 else [\"Init rate\",-1]\n",
    "    data_production_2[\"start_rate\"] = (\n",
    "        data_production_2[\"close_rate\"]\n",
    "        .shift(1)\n",
    "        .where(data_production_2[\"rank\"] != 0, 0)\n",
    "    )\n",
    "\n",
    "    # Write the data_production_2 table to a new Excel file\n",
    "    # change 'date' column type from datetime to date\n",
    "    # Change column type\n",
    "    data_production_3 = data_production_2[[\"ID\", \"Date\", \"close_rate\"]]\n",
    "    data_sales_1 = data_sales_1.drop(columns=[\"date\"])\n",
    "    # Inner join data_sales_1 and data_production_3 tables on 'ID' and 'Date'='week_start' columns\n",
    "    data_sales_1 = data_sales_1.merge(\n",
    "        data_production_3,\n",
    "        left_on=[\"ID\", \"week_start\"],\n",
    "        right_on=[\"ID\", \"Date\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    data_sales_1 = data_sales_1.drop(columns=[\"Date\", \"week_start\"])\n",
    "    data_sales_1.sort_values(\n",
    "        [\"ID\", \"Date Sold\"], ascending=[True, True], inplace=True\n",
    "    )  # Sort table\n",
    "    # Add new column 'Counter' indexing row from 1, do not group by any column\n",
    "    data_sales_1[\"Counter\"] = range(1, len(data_sales_1) + 1)  # Add new column\n",
    "    data_sales_1 = data_sales_1.reset_index(drop=True)  # Reset index\n",
    "\n",
    "    # Add time_retrieved column to both DataFrames\n",
    "    data_production_2[\"time_retrieved\"] = pd.Timestamp.now()\n",
    "    data_sales_1[\"time_retrieved\"] = pd.Timestamp.now()\n",
    "    \n",
    "    # Read date.xlsx file\n",
    "    data_dates = pd.read_excel(\"Date.xlsx\")\n",
    "    data_dates = data_dates[[\"StartOfWeek\", \"WeeklyStartOfMonth\", \"Qtr FY\", \"FY Qtr Start Date\"]]\n",
    "    \n",
    "    # Remove duplicate rows from data_dates table\n",
    "    data_dates.drop_duplicates(subset=[\"StartOfWeek\", \"WeeklyStartOfMonth\"], inplace=True)  # Remove duplicate rows\n",
    "\n",
    "    # Create new dataframe 'monthly_compare' by joining data_production_2 and date.xlsx on 'Date' and 'week_start' columns and take only 'WeekStartOfMonth' column from date.xlsx and whole data_production_2 table\n",
    "    data_production_3 = data_production_2.merge(\n",
    "        data_dates,\n",
    "        left_on=\"Date\",\n",
    "        right_on=\"StartOfWeek\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    data_production_3.drop(columns=[\"StartOfWeek\"], inplace=True)  # Remove column\n",
    "    data_production_3.rename(columns={\"WeeklyStartOfMonth\": \"Month Start\", \"Qtr FY\": \"FYQtr\", \"FY Qtr Start Date\": \"Qtr Start\"}, inplace=True)  # Rename column\n",
    "\n",
    "    # Add new column 'Total Production' in data_production_3 table, using 'Production' * 'Price Submited' columns\n",
    "    data_production_3[\"Total Production\"] = (\n",
    "        data_production_3[\"Production\"] * data_production_3[\"Price Submited\"]\n",
    "    )  # Add new column\n",
    "    # Add new column 'Total Sold' in data_production_3 table, using 'Sold Qty' * 'Mean(Price Sold)' columns\n",
    "    data_production_3[\"Total Sold\"] = (\n",
    "        data_production_3[\"Sold Qty\"] * data_production_3[\"Mean(Price Sold)\"]\n",
    "    )  # Add new column\n",
    "    data_production_3 = data_production_3[['ID', 'Date', 'Month Start', 'Qtr Start', 'FYQtr', 'Model', 'Name', 'Production', 'Total Production', 'Sold Qty', 'Total Sold']]\n",
    "\n",
    "    # Return the two transformed DataFrames\n",
    "    return data_production_2, data_sales_1, data_production_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daf7ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_727/3488206681.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  data_production_2.at[i, \"close_rate\"] = (\n"
     ]
    }
   ],
   "source": [
    "production = pd.read_excel(\"Production.xlsx\")\n",
    "sales = pd.read_excel(\"Sales.xlsx\")\n",
    "data_production, data_sales, data_compare = process_data(production, sales)\n",
    "\n",
    "# Save the dataframes to Excel files\n",
    "data_compare.to_excel(\"Monthly_Compare.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
