{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9ccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b14217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(production, sales):\n",
    "    data_production = production\n",
    "    data_sales = sales\n",
    "    # create new column 'concat' by concatenating 'Model' and 'Name' columns with '.' separator\n",
    "    data_production[\"concat\"] = data_production[\"Model\"] + \".\" + data_production[\"Name\"]  # Concatenate columns\n",
    "    # create new column 'ID' by hashing 'concat' column\n",
    "    data_production[\"ID\"] = data_production[\"concat\"].apply(lambda x: hash(x))  # Hash column\n",
    "    # Remove column 'concat' from data_production table\n",
    "    data_production.drop(columns=[\"concat\"], inplace=True)  # Remove column\n",
    "\n",
    "    # create new column 'concat' by concatenating 'Model' and 'Name' columns with '.' separator\n",
    "    data_sales[\"concat\"] = data_sales[\"Model\"] + \".\" + data_sales[\"Name\"]  # Concatenate columns\n",
    "    # create new column 'ID' by hashing 'concat' column\n",
    "    data_sales[\"ID\"] = data_sales[\"concat\"].apply(lambda x: hash(x))  # Hash column\n",
    "    # Remove column 'concat' from data_production table\n",
    "    data_sales.drop(columns=[\"concat\"], inplace=True)  # Remove column\n",
    "\n",
    "    data_dates = pd.read_excel(\"Date.xlsx\")\n",
    "\n",
    "    # Start processing the data\n",
    "    data_dates = data_dates[[\"Date\", \"StartOfWeek\"]]\n",
    "    data_dates.rename(columns={\"Date\": \"date\", \"StartOfWeek\": \"week_start\"}, inplace=True)  # Rename column\n",
    "    data_dates_1 = data_dates.copy()  # Copy the data_dates table\n",
    "    data_dates_1[\"date_next_week\"] = data_dates_1[\"week_start\"] + pd.DateOffset(7)  # Add 7 days to date\n",
    "\n",
    "    # Join the data_sales and data_sales tables on 'Date Sold' and 'date' columns\n",
    "    data_sales = data_sales.merge(data_dates, left_on=\"Date Sold\", right_on=\"date\", how=\"left\")\n",
    "    data_sales_1 = data_sales.copy()  # Copy the data_sales table\n",
    "\n",
    "    # Add new column 'Sold amt' in data_sales table, using 'Sold Qty' * 'Price Sold' columns\n",
    "    data_sales[\"Sold amt\"] = (data_sales[\"Sold Qty\"] * data_sales[\"Price Sold\"])  # Add new column\n",
    "\n",
    "    # Groupby by 'ID', 'Name', 'week_start' and sum the 'Sold Qty' and 'Sold amt' columns\n",
    "    data_sales_grouped = (data_sales.groupby([\"ID\", \"Name\", \"Model\", \"week_start\"])[[\"Sold Qty\", \"Sold amt\"]].sum().reset_index())\n",
    "\n",
    "    # Add new colum 'Mean(Price Sold)' in data_sales_grouped table, using 'Sold amt' / 'Sold Qty' columns\n",
    "    data_sales_grouped[\"Mean(Price Sold)\"] = (data_sales_grouped[\"Sold amt\"] / data_sales_grouped[\"Sold Qty\"])  # Add new column\n",
    "\n",
    "    # Remove column 'Sold amt' from data_sales_grouped table\n",
    "    data_sales_grouped.drop(columns=\"Sold amt\", inplace=True)  # Remove column\n",
    "\n",
    "    # Join data_sales_grouped with data_production table on 'ID' and 'week_start' columns, with 'ID' and 'Date' columns\n",
    "    data_production = data_production.merge(data_sales_grouped, left_on=[\"ID\", \"Date\"], right_on=[\"ID\", \"week_start\"], how=\"left\")\n",
    "\n",
    "    data_production.drop(columns=[\"Name_y\", \"week_start\"], inplace=True)  # Remove column\n",
    "    data_production.rename(columns={\"Name_x\": \"Name\"}, inplace=True)  # Rename column\n",
    "\n",
    "    # Sort data_production table by 'ID' desc and 'Date' asc columns\n",
    "    data_production.sort_values([\"ID\", \"Date\"], ascending=[False, True], inplace=True)  # Sort table\n",
    "\n",
    "    # Join data_production table with data_dates_1 table on 'Date' and 'date' columns, only keep 'date_next_week' column from data_dates_1 table\n",
    "    data_production = data_production.merge(data_dates_1[[\"date\", \"date_next_week\"]], left_on=\"Date\", right_on=\"date\", how=\"left\")\n",
    "    data_production.drop(columns=[\"date\"], inplace=True)  # Remove column\n",
    "\n",
    "    # Fill missing values in column with float type with 0\n",
    "    data_production[\"Production\"] = data_production[\"Production\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Price Submited\"] = data_production[\"Price Submited\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Sold Qty\"] = data_production[\"Sold Qty\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Mean(Price Sold)\"] = data_production[\"Mean(Price Sold)\"].fillna(0)  # Fill missing values\n",
    "\n",
    "    # Order data_production table by 'ID' and 'Date' columns\n",
    "    data_production.sort_values([\"ID\", \"Date\"], inplace=True)  # Sort table\n",
    "\n",
    "    # Add cumulative sum column 'Running Sold' of 'Sum(Sold Qty)' column by 'ID' group\n",
    "    data_production_1 = data_production.copy()  # Copy the data_production table\n",
    "    data_production_1[\"Running Sold\"] = data_production_1.groupby(\"ID\")[\"Sold Qty\"].cumsum()  # Add new column\n",
    "\n",
    "    # Add cumulative sum column 'Running Production' of 'Production' column by 'ID' group\n",
    "    data_production_1[\"Running Production\"] = data_production_1.groupby(\"ID\")[\"Production\"].cumsum()  # Add new column\n",
    "    data_production_1 = data_production_1.drop(columns=[\"Name\", \"Date\", \"Price Submited\", \"Sold Qty\", \"Mean(Price Sold)\"])  # Remove columns\n",
    "    data_production_2 = data_production.merge(data_production_1, left_on=[\"Date\", \"ID\"], right_on=[\"date_next_week\", \"ID\"], how=\"left\")  # Merge tables\n",
    "    print(data_production_2.columns)\n",
    "    # Keep columns 'ID', 'Name', 'Date', 'Production', 'Price Submited', 'Sold Qty', 'Mean(Price Sold)', 'Running Sold', 'Running Production'\n",
    "    data_production_2 = data_production_2[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Model_x\"\n",
    "            \"Name\",\n",
    "            \"Date\",\n",
    "            \"Production_x\",\n",
    "            \"Price Submited\",\n",
    "            \"Sold Qty\",\n",
    "            \"Mean(Price Sold)\",\n",
    "            \"Running Sold\",\n",
    "            \"Running Production\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # rename columns 'ID_x', 'Production_x' to 'ID', 'Production'\n",
    "    data_production_2.rename(columns={\"ID_x\": \"ID\", \"Production_x\": \"Production\", \"Model_x\": \"Model\"}, inplace=True)  # Rename columns\n",
    "    data_production_2[\"Production\"] = data_production_2[\"Production\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Price Submited\"] = data_production_2[\"Price Submited\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Sold Qty\"] = data_production_2[\"Sold Qty\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Mean(Price Sold)\"] = data_production_2[\"Mean(Price Sold)\" ].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Running Sold\"] = data_production_2[\"Running Sold\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Running Production\"] = data_production_2[\"Running Production\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Opening\"] = (data_production_2[\"Running Production\"] - data_production_2[\"Running Sold\"])  # Add new column\n",
    "    data_production_2[\"Available\"] = (data_production_2[\"Production\"] + data_production_2[\"Opening\"])  # Add new column\n",
    "    data_production_2[\"Closing\"] = (data_production_2[\"Available\"] - data_production_2[\"Sold Qty\"])  # Add new column data_production_2\n",
    "    data_production_2[\"rank\"] = data_production_2.groupby(\"ID\").cumcount()\n",
    "\n",
    "    # Add new column 'prev_available' with logic: if \"ID\" = [\"ID\",-1] then [\"Available\",-1] else 0\n",
    "    if not data_production_2[\"ID\"].shift(1).isnull().all():\n",
    "        data_production_2[\"prev_available\"] = (\n",
    "            data_production_2[\"Available\"]\n",
    "            .shift(1)\n",
    "            .where(data_production_2[\"ID\"] == data_production_2[\"ID\"].shift(1), 0)\n",
    "        )\n",
    "        \n",
    "    data_production_2[\"prev_closing\"] = data_production_2.apply(lambda row: 0 if row[\"prev_available\"] == 0 else data_production_2.loc[row.name - 1, \"Closing\"] if row.name > 0 else 0, axis=1,)\n",
    "    data_production_2[\"close_rate\"] = 0.0\n",
    "\n",
    "    # Iterate through each row to calculate 'Init rate'\n",
    "    for i in range(len(data_production_2)):\n",
    "        if data_production_2.at[i, \"rank\"] == 0:\n",
    "            data_production_2.at[i, \"close_rate\"] = data_production_2.at[\n",
    "                i, \"Price Submited\"\n",
    "            ]\n",
    "        else:\n",
    "            # Calculate using the formula with previous 'Init rate'\n",
    "            previous_init_rate = data_production_2.at[i - 1, \"close_rate\"]\n",
    "            stock_available = data_production_2.at[i, \"prev_closing\"]\n",
    "            production_weight = data_production_2.at[i, \"Production\"]\n",
    "            production_rate = data_production_2.at[i, \"Price Submited\"]\n",
    "\n",
    "            data_production_2.at[i, \"close_rate\"] = (\n",
    "                stock_available * previous_init_rate\n",
    "                + production_weight * production_rate\n",
    "            ) / (stock_available + production_weight) # data_production_2\n",
    "    data_production_2.sort_values([\"ID\", \"rank\"], ascending=[True, True], inplace=True)  # Sort table\n",
    "\n",
    "    # Add new column 'start_rate' with logic: if \"rank\" = 0 then 0 else [\"Init rate\",-1]\n",
    "    data_production_2[\"start_rate\"] = (\n",
    "        data_production_2[\"close_rate\"]\n",
    "        .shift(1)\n",
    "        .where(data_production_2[\"rank\"] != 0, 0)\n",
    "    )\n",
    "\n",
    "    # Write the data_production_2 table to a new Excel file\n",
    "    # change 'date' column type from datetime to date\n",
    "    # Change column type\n",
    "    data_production_3 = data_production_2[[\"ID\", \"Date\", \"close_rate\"]]\n",
    "    data_sales_1 = data_sales_1.drop(columns=[\"date\"])\n",
    "    # Inner join data_sales_1 and data_production_3 tables on 'ID' and 'Date'='week_start' columns\n",
    "    data_sales_1 = data_sales_1.merge(\n",
    "        data_production_3,\n",
    "        left_on=[\"ID\", \"week_start\"],\n",
    "        right_on=[\"ID\", \"Date\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    data_sales_1 = data_sales_1.drop(columns=[\"Date\", \"week_start\"])\n",
    "    data_sales_1.sort_values(\n",
    "        [\"ID\", \"Date Sold\"], ascending=[True, True], inplace=True\n",
    "    )  # Sort table\n",
    "    # Add new column 'Counter' indexing row from 1, do not group by any column\n",
    "    data_sales_1[\"Counter\"] = range(1, len(data_sales_1) + 1)  # Add new column\n",
    "    data_sales_1 = data_sales_1.reset_index(drop=True)  # Reset index\n",
    "\n",
    "    # Add time_retrieved column to both DataFrames\n",
    "    data_production_2[\"time_retrieved\"] = pd.Timestamp.now()\n",
    "    data_sales_1[\"time_retrieved\"] = pd.Timestamp.now()\n",
    "    # Return the two transformed DataFrames\n",
    "    return data_production_2, data_sales_1\n",
    "\n",
    "production = pd.read_excel(\"Production.xlsx\")\n",
    "sales = pd.read_excel(\"Sales.xlsx\")\n",
    "data_production, data_sales = process_data(production, sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daf7ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model_x_x', 'ID', 'Name', 'Price Submited', 'Production_x', 'Date',\n",
      "       'Model_y_x', 'Sold Qty', 'Mean(Price Sold)', 'date_next_week_x',\n",
      "       'Model_x_y', 'Production_y', 'Model_y_y', 'date_next_week_y',\n",
      "       'Running Sold', 'Running Production'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Model_xName'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m production = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33mProduction.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m sales = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33mSales.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m data_production, data_sales = \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msales\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# view data_production\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# print(data_production.head())\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mprocess_data\u001b[39m\u001b[34m(production, sales)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(data_production_2.columns)\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Keep columns 'ID', 'Name', 'Date', 'Production', 'Price Submited', 'Sold Qty', 'Mean(Price Sold)', 'Running Sold', 'Running Production'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m data_production_2 = \u001b[43mdata_production_2\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModel_x\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mName\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProduction_x\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPrice Submited\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSold Qty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMean(Price Sold)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRunning Sold\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRunning Production\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# rename columns 'ID_x', 'Production_x' to 'ID', 'Production'\u001b[39;00m\n\u001b[32m     90\u001b[39m data_production_2.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mID_x\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mID\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProduction_x\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mProduction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mModel_x\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Rename columns\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Model_xName'] not in index\""
     ]
    }
   ],
   "source": [
    "production = pd.read_excel(\"Production.xlsx\")\n",
    "sales = pd.read_excel(\"Sales.xlsx\")\n",
    "data_production, data_sales = process_data(production, sales)\n",
    "\n",
    "# view data_production\n",
    "# print(data_production.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1967f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
