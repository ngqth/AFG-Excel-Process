{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9ccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b14217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(production, sales):\n",
    "    data_production = production\n",
    "    id_name = data_production[[\"ID\", \"Name\"]].drop_duplicates()\n",
    "    data_sales = sales\n",
    "    data_sales = data_sales.merge(id_name, on=\"ID\", how=\"left\")\n",
    "    data_dates = pd.read_excel(\"Date.xlsx\")\n",
    "\n",
    "    # Start processing the data\n",
    "    data_dates = data_dates[[\"Date\", \"StartOfWeek\"]]\n",
    "    data_dates.rename(columns={\"Date\": \"date\", \"StartOfWeek\": \"week_start\"}, inplace=True)  # Rename column\n",
    "    data_dates_1 = data_dates.copy()  # Copy the data_dates table\n",
    "    data_dates_1[\"date_next_week\"] = data_dates_1[\"week_start\"] + pd.DateOffset(7)  # Add 7 days to date\n",
    "    # Join the data_sales and data_sales tables on 'Date Sold' and 'date' columns\n",
    "    data_sales = data_sales.merge(data_dates, left_on=\"Date Sold\", right_on=\"date\", how=\"left\")\n",
    "    data_sales_1 = data_sales.copy()  # Copy the data_sales table\n",
    "    # Add new column 'Sold amt' in data_sales table, using 'Sold Qty' * 'Price Sold' columns\n",
    "    data_sales[\"Sold amt\"] = (data_sales[\"Sold Qty\"] * data_sales[\"Price Sold\"])  # Add new column\n",
    "    # Groupby by 'ID', 'Name', 'week_start' and sum the 'Sold Qty' and 'Sold amt' columns\n",
    "    data_sales_grouped = (\n",
    "        data_sales.groupby([\"ID\", \"Name\", \"week_start\"])[[\"Sold Qty\", \"Sold amt\"]]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Add new colum 'Mean(Price Sold)' in data_sales_grouped table, using 'Sold amt' / 'Sold Qty' columns\n",
    "    data_sales_grouped[\"Mean(Price Sold)\"] = (data_sales_grouped[\"Sold amt\"] / data_sales_grouped[\"Sold Qty\"])  # Add new column\n",
    "    # Remove column 'Sold amt' from data_sales_grouped table\n",
    "    data_sales_grouped.drop(columns=\"Sold amt\", inplace=True)  # Remove column\n",
    "    # Join data_sales_grouped with data_production table on 'ID' and 'week_start' columns, with 'ID' and 'Date' columns\n",
    "    data_production = data_production.merge(\n",
    "        data_sales_grouped,\n",
    "        left_on=[\"ID\", \"Date\"],\n",
    "        right_on=[\"ID\", \"week_start\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    data_production.drop(columns=[\"Name_y\", \"week_start\"], inplace=True)  # Remove column\n",
    "    data_production.rename(columns={\"Name_x\": \"Name\"}, inplace=True)  # Rename column\n",
    "    # Sort data_production table by 'ID' desc and 'Date' asc columns\n",
    "    data_production.sort_values([\"ID\", \"Date\"], ascending=[False, True], inplace=True)  # Sort table\n",
    "    # Join data_production table with data_dates_1 table on 'Date' and 'date' columns, only keep 'date_next_week' column from data_dates_1 table\n",
    "    data_production = data_production.merge(\n",
    "        data_dates_1[[\"date\", \"date_next_week\"]],\n",
    "        left_on=\"Date\",\n",
    "        right_on=\"date\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    data_production.drop(columns=[\"date\"], inplace=True)  # Remove column\n",
    "\n",
    "    # Fill missing values in column with float type with 0\n",
    "    data_production[\"Production\"] = data_production[\"Production\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Price Submited\"] = data_production[\"Price Submited\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Sold Qty\"] = data_production[\"Sold Qty\"].fillna(0)  # Fill missing values\n",
    "    data_production[\"Mean(Price Sold)\"] = data_production[\"Mean(Price Sold)\"].fillna(0)  # Fill missing values\n",
    "\n",
    "    # Order data_production table by 'ID' and 'Date' columns\n",
    "    data_production.sort_values([\"ID\", \"Date\"], inplace=True)  # Sort table\n",
    "\n",
    "    # Add cumulative sum column 'Running Sold' of 'Sum(Sold Qty)' column by 'ID' group\n",
    "    data_production_1 = data_production.copy()  # Copy the data_production table\n",
    "    data_production_1[\"Running Sold\"] = data_production_1.groupby(\"ID\")[\"Sold Qty\"].cumsum()  # Add new column\n",
    "\n",
    "    # Add cumulative sum column 'Running Production' of 'Production' column by 'ID' group\n",
    "    data_production_1[\"Running Production\"] = data_production_1.groupby(\"ID\")[\"Production\"].cumsum()  # Add new column\n",
    "    data_production_1 = data_production_1.drop(columns=[\"Name\", \"Date\", \"Price Submited\", \"Sold Qty\", \"Mean(Price Sold)\"])  # Remove columns\n",
    "    data_production_2 = data_production.merge(\n",
    "        data_production_1,\n",
    "        left_on=[\"Date\", \"ID\"],\n",
    "        right_on=[\"date_next_week\", \"ID\"],\n",
    "        how=\"left\",\n",
    "    )  # Merge tables\n",
    "\n",
    "    # Keep columns 'ID', 'Name', 'Date', 'Production', 'Price Submited', 'Sold Qty', 'Mean(Price Sold)', 'Running Sold', 'Running Production'\n",
    "    data_production_2 = data_production_2[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Name\",\n",
    "            \"Date\",\n",
    "            \"Production_x\",\n",
    "            \"Price Submited\",\n",
    "            \"Sold Qty\",\n",
    "            \"Mean(Price Sold)\",\n",
    "            \"Running Sold\",\n",
    "            \"Running Production\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # rename columns 'ID_x', 'Production_x' to 'ID', 'Production'\n",
    "    data_production_2.rename(columns={\"ID_x\": \"ID\", \"Production_x\": \"Production\"}, inplace=True)  # Rename columns\n",
    "    data_production_2[\"Production\"] = data_production_2[\"Production\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Price Submited\"] = data_production_2[\"Price Submited\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Sold Qty\"] = data_production_2[\"Sold Qty\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Mean(Price Sold)\"] = data_production_2[\"Mean(Price Sold)\" ].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Running Sold\"] = data_production_2[\"Running Sold\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Running Production\"] = data_production_2[\"Running Production\"].fillna(0)  # Fill missing values\n",
    "    data_production_2[\"Opening\"] = (data_production_2[\"Running Production\"] - data_production_2[\"Running Sold\"])  # Add new column\n",
    "    data_production_2[\"Available\"] = (data_production_2[\"Production\"] + data_production_2[\"Opening\"])  # Add new column\n",
    "    data_production_2[\"Closing\"] = (data_production_2[\"Available\"] - data_production_2[\"Sold Qty\"])  # Add new column data_production_2\n",
    "    data_production_2[\"rank\"] = data_production_2.groupby(\"ID\").cumcount()\n",
    "    # Add new column 'prev_available' with logic: if \"ID\" = [\"ID\",-1] then [\"Available\",-1] else 0\n",
    "    if not data_production_2[\"ID\"].shift(1).isnull().all():\n",
    "        data_production_2[\"prev_available\"] = (\n",
    "            data_production_2[\"Available\"]\n",
    "            .shift(1)\n",
    "            .where(data_production_2[\"ID\"] == data_production_2[\"ID\"].shift(1), 0)\n",
    "        )\n",
    "        \n",
    "    data_production_2[\"prev_closing\"] = data_production_2.apply(lambda row: 0 if row[\"prev_available\"] == 0 else data_production_2.loc[row.name - 1, \"Closing\"] if row.name > 0 else 0, axis=1,)\n",
    "    data_production_2[\"close_rate\"] = 0.0\n",
    "\n",
    "    # Iterate through each row to calculate 'Init rate'\n",
    "    for i in range(len(data_production_2)):\n",
    "        if data_production_2.at[i, \"rank\"] == 0:\n",
    "            data_production_2.at[i, \"close_rate\"] = data_production_2.at[\n",
    "                i, \"Price Submited\"\n",
    "            ]\n",
    "        else:\n",
    "            # Calculate using the formula with previous 'Init rate'\n",
    "            previous_init_rate = data_production_2.at[i - 1, \"close_rate\"]\n",
    "            stock_available = data_production_2.at[i, \"prev_closing\"]\n",
    "            production_weight = data_production_2.at[i, \"Production\"]\n",
    "            production_rate = data_production_2.at[i, \"Price Submited\"]\n",
    "\n",
    "            data_production_2.at[i, \"close_rate\"] = (\n",
    "                stock_available * previous_init_rate\n",
    "                + production_weight * production_rate\n",
    "            ) / (stock_available + production_weight) # data_production_2\n",
    "    data_production_2.sort_values([\"ID\", \"rank\"], ascending=[True, True], inplace=True)  # Sort table\n",
    "\n",
    "    # Add new column 'start_rate' with logic: if \"rank\" = 0 then 0 else [\"Init rate\",-1]\n",
    "    data_production_2[\"start_rate\"] = (\n",
    "        data_production_2[\"close_rate\"]\n",
    "        .shift(1)\n",
    "        .where(data_production_2[\"rank\"] != 0, 0)\n",
    "    )\n",
    "\n",
    "    # Write the data_production_2 table to a new Excel file\n",
    "    # change 'date' column type from datetime to date\n",
    "    # Change column type\n",
    "    data_production_3 = data_production_2[[\"ID\", \"Date\", \"close_rate\"]]\n",
    "    data_sales_1 = data_sales_1.drop(columns=[\"date\"])\n",
    "    # Inner join data_sales_1 and data_production_3 tables on 'ID' and 'Date'='week_start' columns\n",
    "    data_sales_1 = data_sales_1.merge(\n",
    "        data_production_3,\n",
    "        left_on=[\"ID\", \"week_start\"],\n",
    "        right_on=[\"ID\", \"Date\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    data_sales_1 = data_sales_1.drop(columns=[\"Date\", \"week_start\"])\n",
    "    data_sales_1.sort_values(\n",
    "        [\"ID\", \"Date Sold\"], ascending=[True, True], inplace=True\n",
    "    )  # Sort table\n",
    "    # Add new column 'Counter' indexing row from 1, do not group by any column\n",
    "    data_sales_1[\"Counter\"] = range(1, len(data_sales_1) + 1)  # Add new column\n",
    "    data_sales_1 = data_sales_1.reset_index(drop=True)  # Reset index\n",
    "\n",
    "    # Add time_retrieved column to both DataFrames\n",
    "    data_production_2[\"time_retrieved\"] = pd.Timestamp.now()\n",
    "    data_sales_1[\"time_retrieved\"] = pd.Timestamp.now()\n",
    "    # Return the two transformed DataFrames\n",
    "    return data_production_2, data_sales_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7ae6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Production.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m production = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../Production.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m sales = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33m../Sales.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m data_production, data_sales = process_data(production, sales)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/excel/_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/excel/_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../Production.xlsx'"
     ]
    }
   ],
   "source": [
    "production = pd.read_excel(\"../\")\n",
    "sales = pd.read_excel(\"../Sales.xlsx\")\n",
    "data_production, data_sales = process_data(production, sales)\n",
    "\n",
    "# view data_production\n",
    "print(data_production.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1967f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
